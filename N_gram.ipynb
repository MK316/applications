{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N-gram.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6gw73xPeeTRhSYJdenYfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/applications/blob/main/N_gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic: N-gram\n",
        "\n",
        "Corpus Toolkit: Source from [Kristopher Kyle](\"https://github.com/kristopherkyle/corpus_toolkit\")"
      ],
      "metadata": {
        "id": "p516AzDlpiqR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpXLO2bZphqM",
        "outputId": "37bd2863-bc70-4779-8a3e-613e68a24422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting corpus-toolkit\n",
            "  Downloading corpus_toolkit-0.32-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: corpus-toolkit\n",
            "Successfully installed corpus-toolkit-0.32\n"
          ]
        }
      ],
      "source": [
        "#@markdown Install {Corpus Toolkit}\n",
        "\n",
        "!pip install corpus-toolkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Bring the data (Brown corpus single) from github to Colab server:\n",
        "# Format: !git clone https://github.com/youraccountname/repositoryname/brown_single.git\n",
        "!git clone https://github.com/MK316/mynltkdata.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "FBy0CwJzpupo",
        "outputId": "196a46f2-40f5-4f03-ba68-08df3a794940"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mynltkdata'...\n",
            "remote: Enumerating objects: 588, done.\u001b[K\n",
            "remote: Counting objects:   6% (1/15)\u001b[K\rremote: Counting objects:  13% (2/15)\u001b[K\rremote: Counting objects:  20% (3/15)\u001b[K\rremote: Counting objects:  26% (4/15)\u001b[K\rremote: Counting objects:  33% (5/15)\u001b[K\rremote: Counting objects:  40% (6/15)\u001b[K\rremote: Counting objects:  46% (7/15)\u001b[K\rremote: Counting objects:  53% (8/15)\u001b[K\rremote: Counting objects:  60% (9/15)\u001b[K\rremote: Counting objects:  66% (10/15)\u001b[K\rremote: Counting objects:  73% (11/15)\u001b[K\rremote: Counting objects:  80% (12/15)\u001b[K\rremote: Counting objects:  86% (13/15)\u001b[K\rremote: Counting objects:  93% (14/15)\u001b[K\rremote: Counting objects: 100% (15/15)\u001b[K\rremote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 588 (delta 4), reused 0 (delta 0), pack-reused 573\u001b[K\n",
            "Receiving objects: 100% (588/588), 4.89 MiB | 18.96 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Change current directory to /brown_single/:\n",
        "%cd /content/mynltkdata/\n",
        "\n",
        "current = %pwd\n",
        "print('Current directory: %s'%current)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNrS9RP8rDAv",
        "outputId": "c215121e-5f8a-463b-f6f2-c52809c51bec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mynltkdata\n",
            "Current directory: /content/mynltkdata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Import {os} to see files in the current directory:\n",
        "import os\n",
        "print(len(os.listdir('/content/mynltkdata/brown_single/'))) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kyAY8vWrx4o",
        "outputId": "8fa7783d-1736-476c-c5e0-af04914f4356"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes: Codes to know\n",
        "Refresh file folder when there's any change:\n",
        "~~~\n",
        "!git pull\n",
        "~~~\n",
        "Current directory:\n",
        "~~~\n",
        "%pwd\n",
        "~~~"
      ],
      "metadata": {
        "id": "8t3xNX4usXYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Tokenize texts (500 files) and do a frequency analysis:\n",
        "from corpus_toolkit import corpus_tools as ct\n",
        "brown_corp = ct.ldcorpus(\"brown_single\") #load and read corpus\n",
        "tok_corp = ct.tokenize(brown_corp) #tokenize corpus - by default this lemmatizes as well\n",
        "brown_freq = ct.frequency(tok_corp) #creates a frequency dictionary"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Bj4H9FiYsJ5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Number of tokens analyzed:\n",
        "leng = len(brown_freq)\n",
        "print('Number of tokens: %d'%leng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "JPr9CefutWLz",
        "outputId": "c6df81d0-0cae-45da-ce6b-c9517b5750d4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens: 36377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Try finding a word: 'type a word to look up'\n",
        "word_to_search = input()\n",
        "\n",
        "result = brown_freq[word_to_search]\n",
        "print('\"%s\" :'%word_to_search, ' %d'%result, ' occurrence(s) in this corpus.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "luC1NUUXtvGN",
        "outputId": "56cca7ff-ccf8-48ef-a783-3e761690c4c9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "however\n",
            "\"however\" :  552  occurrence(s) in this corpus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collocation: cases of word1 used with word *2* "
      ],
      "metadata": {
        "id": "N1BntsrqvGFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Search concordance: change word1, word2 as you want\n",
        "#@markdown current word1 = 'run', 'runs', 'ran', 'running'\n",
        "\n",
        "#@markdown current word2 = 'quickly', 'quick'\n",
        "\n",
        "%%capture\n",
        "conc_results2 = ct.concord(ct.tokenize(ct.ldcorpus(\"brown_single\"),lemma = False),[\"run\",\"ran\",\"running\",\"runs\"],collocates = [\"quick\",\"quickly\"], nhits = 10)"
      ],
      "metadata": {
        "id": "n16wC3mru9zU"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in conc_results2:\n",
        "\tprint(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJypfHk-vaFt",
        "outputId": "aeb25833-a790-414f-f530-af8cfab58929"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['engine', 'up', 'to', 'operating', 'temperature', 'quickly', 'and', 'to', 'keep', 'it'], 'running', ['at', 'its', 'most', 'efficient', 'temperature', 'through', 'the', 'proper', 'circulation', 'of']]\n",
            "[['hands', 'and', 'feet', 'keeping', 'the', 'hands', 'in', 'the', 'starting', 'position'], 'run', ['in', 'place', 'to', 'a', 'quick', 'rhythm', 'after', 'this', 'has', 'become']]\n",
            "[['range', 'and', 'in', 'marlin', 's', 'underground', 'test', 'gallery', 'we', 'quickly'], 'ran', ['into', 'the', 'same', 'trouble', 'that', 'plagued', 'bill', 'ruger', 'in', 'his']]\n",
            "[['s', 'nest', 'to', 'the', 'rocky', 'ribs', 'of', 'the', 'canyonside', 'russ'], 'ran', ['up', 'the', 'steps', 'quickly', 'to', 'the', 'plank', 'porch', 'the', 'front']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Ignore this part (left out for future)\n",
        "# word1 = input()\n",
        "# # word1 = [int(e) if e.isdigit() else e for e in word1.split(',')]\n",
        "# word2 = input()\n",
        "# # word2 = [int(e) if e.isdigit() else e for e in word2.split(',')]\n",
        "# conc_results2 = ct.concord(ct.tokenize(ct.ldcorpus(\"brown_single\"),lemma = False), [word1], collocates = [word2], nhits = 10)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0oO23BZPvkBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Searching example using regular expressions:\n",
        "%%capture\n",
        "conc_results3 = ct.concord(ct.tokenize(ct.ldcorpus(\"brown_single\"),lemma = False),[\"run.*\",\"ran\"],collocates = [\"quick.*\"], nhits = 10, regex = True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hoEBqEphv0o1"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Show result: \n",
        "for x in conc_results3:\n",
        "\tprint(x)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QEWiX7bV1IjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Single word collocator: e.g., 'go'\n",
        "%%capture\n",
        "collocates = ct.collocator(ct.tokenize(ct.ldcorpus(\"brown_single\")),\"go\",stat = \"MI\")\n",
        "#stat options include: \"MI\", \"T\", \"freq\", \"left\", and \"right\""
      ],
      "metadata": {
        "id": "k5OQWtx01M2E"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show result\n",
        "ct.head(collocates, hits = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szl2d5aH1hIS",
        "outputId": "fb7941fb-47ad-4677-d16a-c0e7f59d3751"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downstairs\t7.875170389265524\n",
            "upstairs\t6.915812373762869\n",
            "bedroom\t6.627242875821938\n",
            "abroad\t6.273134375185426\n",
            "re\t6.21620730710059\n",
            "m\t6.211322724303333\n",
            "forever\t6.174730671124432\n",
            "stanley\t6.174730671124432\n",
            "let\t5.938347287580174\n",
            "wrong\t5.868744120106091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N-grams\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "N-grams are contiguous sequences of n words. The tokenize() function can be used to create an n-gram version of a corpus by employing the ngram argument. By default, words in an n-gram are separated by two underscores \"__\""
      ],
      "metadata": {
        "id": "xA3UYsrX1vZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown N-gram: e.g., type 3 => 3 words in sequences:\n",
        "ngram_n = input()\n",
        "n1 = int(ngram_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "9D_Z7Qe224oJ",
        "outputId": "e316ec91-5e62-4340-c017-e2f03d26d20d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Run n-gram analyzer\n",
        "%%capture\n",
        "trigramfreq = ct.frequency(ct.tokenize(ct.ldcorpus(\"brown_single\"),lemma = False, ngram = n1))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Pz2Jpy_y1p5Q"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Show results:\n",
        "\n",
        "ct.head(trigramfreq, hits = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "LGrly_Mx2pfk",
        "outputId": "d5eb1af6-28c9-4ced-adc8-fe9600590a15"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "of__the__united__states\t111\n",
            "at__the__same__time\t87\n",
            "the__end__of__the\t77\n",
            "in__the__united__states\t70\n",
            "at__the__end__of\t63\n",
            "one__of__the__most\t58\n",
            "on__the__other__hand\t58\n",
            "the__rest__of__the\t57\n",
            "on__the__basis__of\t56\n",
            "i__do__nt__know\t53\n"
          ]
        }
      ]
    }
  ]
}